Strategies:
	Word-Level: Training data costly to produce, shows poor correlation with sentence-level quality estimation.
		- Labels can be automatically generated by TERCOM through the use of post-edits.
	Sentence-Level: Most training data available (various language pairs), costly to produce annotated data, no data for specific domains.
		- Can use labels from post-edits: system produces sentence, annotator post-edits it, HTER score is calculated.
		- Alternative: use HTER between sentence produced/gold-standard.
	Document-Level: New task, no manually produced/annotated data available. Scores commonly generated automatically (cheap, domain/language-agnostic).
		- Meteor is usually a gold-standard for paragraph-level, could be used for free.
	Grammatical Error Identification: Could be more practical, but no language independent tools are available.
	Combinations: Combining automatically generated Word/Sentence/Document-Level QE scores could yield a more reliable and robust quality measure.
		- A single post-edit that preserves the number/order of sentences produced by the translation system could be used for all three levels.
		
Suggestion 1:
	1) Use gold-standard used to train Iconic engines as post-edits or produce structure-preserving post-edits for some translations produced by the Iconic engines.
	2) Use automatically generated metrics (TERCOM, HTER, Meteor) between post-edits and produced translation to generate annotated data.
	3) Train prediction models using QuEst++, or quality labels using the BinQE strategy.

Suggestion 2:
	1) Use automatically generated metrics (TERCOM, HTER, Meteor) between gold-standard used to train Iconic engines and produced translation to generate annotated data.
	2) Train prediction models using QuEst++.
	
Suggestion 3:
	1) Use gold-standard used to train Iconic engines as post-edits.
	2) Use translations produced by some other engine as a reference translation.
	3) Create scripts to produce labels such as the ones in BinQE.
	4) Generate large datasets for domain-specific translation pairs.
	5) Train various learning models with features extracted.